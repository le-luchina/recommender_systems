{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8861eac9",
   "metadata": {},
   "source": [
    
    "## Collaborative Filtering recommender system\n",
    "### with NN embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d523550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim import corpora\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8094fcb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889878</td>\n",
       "      <td>CC0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1342067</td>\n",
       "      <td>CL0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990814</td>\n",
       "      <td>ML0120ENv3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380098</td>\n",
       "      <td>BD0211EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>779563</td>\n",
       "      <td>DS0101EN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user        item  rating\n",
       "0  1889878    CC0101EN     3.0\n",
       "1  1342067    CL0101EN     3.0\n",
       "2  1990814  ML0120ENv3     3.0\n",
       "3   380098    BD0211EN     3.0\n",
       "4   779563    DS0101EN     3.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading data\n",
    "rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv\"\n",
    "rating_df = pd.read_csv(rating_url)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb59279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique items & users for latent feature vectors construction\n",
    "num_users = len(rating_df['user'].unique())\n",
    "num_items = len(rating_df['item'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "998da3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining recommender net sub class, inheriting from tensorflow.keras.Model\n",
    "class RecommenderNet(keras.Model):\n",
    "    \n",
    "    def __init__(self, num_users, num_items, embedding_size=16, **kwargs):\n",
    "        \"\"\"Constructor\n",
    "           :param int num_users: number of users\n",
    "           :param int num_items: number of items\n",
    "           :param int embedding_size: the size of embedding vector\"\"\"\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        #defining user_embedding vector\n",
    "        self.user_embedding_layer = layers.Embedding(\n",
    "            input_dim=num_users,\n",
    "            output_dim=embedding_size,\n",
    "            name='user_embedding_layer',\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6))\n",
    "        # defining user bias layer\n",
    "        self.user_bias = layers.Embedding(\n",
    "            input_dim=num_users,\n",
    "            output_dim=1,\n",
    "            name=\"user_bias\")\n",
    "        \n",
    "        # defining item_embedding vector\n",
    "        self.item_embedding_layer = layers.Embedding(\n",
    "            input_dim=num_items,\n",
    "            output_dim=embedding_size,\n",
    "            name='item_embedding_layer',\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6))\n",
    "        # defining item bias layer\n",
    "        self.item_bias = layers.Embedding(\n",
    "            input_dim=num_items,\n",
    "            output_dim=1,\n",
    "            name=\"item_bias\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"method to be called during model fitting           \n",
    "           :param inputs: user and item one-hot vectors\"\"\"\n",
    "        # computing user and item embedding vectors\n",
    "        user_vector = self.user_embedding_layer(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        item_vector = self.item_embedding_layer(inputs[:, 1])\n",
    "        item_bias = self.item_bias(inputs[:, 1])\n",
    "        dot_user_item = tf.tensordot(user_vector, item_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_item + user_bias + item_bias\n",
    "        # Sigmoid output layer to output the probability\n",
    "        return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "119248c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convering original data to iniciees for one hot vectors for tensorflow processing\n",
    "def process_dataset(raw_data):\n",
    "    \n",
    "    encoded_data = raw_data.copy()\n",
    "    \n",
    "    # Mapping user ids to indices\n",
    "    user_list = encoded_data[\"user\"].unique().tolist()\n",
    "    user_id2idx_dict = {x: i for i, x in enumerate(user_list)}\n",
    "    user_idx2id_dict = {i: x for i, x in enumerate(user_list)}\n",
    "    \n",
    "    # Mapping course ids to indices\n",
    "    course_list = encoded_data[\"item\"].unique().tolist()\n",
    "    course_id2idx_dict = {x: i for i, x in enumerate(course_list)}\n",
    "    course_idx2id_dict = {i: x for i, x in enumerate(course_list)}\n",
    "\n",
    "    # Convert original user ids to idx\n",
    "    encoded_data[\"user\"] = encoded_data[\"user\"].map(user_id2idx_dict)\n",
    "    # Convert original course ids to idx\n",
    "    encoded_data[\"item\"] = encoded_data[\"item\"].map(course_id2idx_dict)\n",
    "    # Convert rating to int\n",
    "    encoded_data[\"rating\"] = encoded_data[\"rating\"].values.astype(\"int\")\n",
    "\n",
    "    return encoded_data, user_idx2id_dict, course_idx2id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171ac5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0     0       3\n",
       "1     1     1       3\n",
       "2     2     2       3\n",
       "3     3     3       3\n",
       "4     4     4       3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data, user_idx2id_dict, course_idx2id_dict = process_dataset(rating_df)\n",
    "encoded_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0885edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating custom split for train, validation and test sets\n",
    "def generate_train_test_datasets(dataset, scale=True):\n",
    "\n",
    "    min_rating = min(dataset[\"rating\"])\n",
    "    max_rating = max(dataset[\"rating\"])\n",
    "\n",
    "    dataset = dataset.sample(frac=1, random_state=42)\n",
    "    x = dataset[[\"user\", \"item\"]].values\n",
    "    if scale:\n",
    "        y = dataset[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values\n",
    "    else:\n",
    "        y = dataset[\"rating\"].values\n",
    "\n",
    "    # Assuming training on 80% of the data and validating on 10%, and testing 10%\n",
    "    train_indices = int(0.8 * dataset.shape[0])\n",
    "    test_indices = int(0.9 * dataset.shape[0])\n",
    "\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = (\n",
    "        x[:train_indices],\n",
    "        x[train_indices:test_indices],\n",
    "        x[test_indices:],\n",
    "        y[:train_indices],\n",
    "        y[train_indices:test_indices],\n",
    "        y[test_indices:],\n",
    "    )\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517d155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = generate_train_test_datasets(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf5390f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2917/2917 [==============================] - 37s 12ms/step - loss: 0.1415 - root_mean_squared_error: 0.3758 - val_loss: 0.0466 - val_root_mean_squared_error: 0.2148\n",
      "Epoch 2/10\n",
      "2917/2917 [==============================] - 34s 12ms/step - loss: 0.0397 - root_mean_squared_error: 0.1977 - val_loss: 0.0409 - val_root_mean_squared_error: 0.2004\n",
      "Epoch 3/10\n",
      "2917/2917 [==============================] - 32s 11ms/step - loss: 0.0279 - root_mean_squared_error: 0.1643 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1641\n",
      "Epoch 4/10\n",
      "2917/2917 [==============================] - 32s 11ms/step - loss: 0.0214 - root_mean_squared_error: 0.1425 - val_loss: 0.0237 - val_root_mean_squared_error: 0.1499\n",
      "Epoch 5/10\n",
      "2917/2917 [==============================] - 32s 11ms/step - loss: 0.0179 - root_mean_squared_error: 0.1286 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1417\n",
      "Epoch 6/10\n",
      "2917/2917 [==============================] - 32s 11ms/step - loss: 0.0153 - root_mean_squared_error: 0.1177 - val_loss: 0.0201 - val_root_mean_squared_error: 0.1364\n",
      "Epoch 7/10\n",
      "2917/2917 [==============================] - 28s 10ms/step - loss: 0.0134 - root_mean_squared_error: 0.1091 - val_loss: 0.0190 - val_root_mean_squared_error: 0.1320\n",
      "Epoch 8/10\n",
      "2917/2917 [==============================] - 30s 10ms/step - loss: 0.0119 - root_mean_squared_error: 0.1015 - val_loss: 0.0179 - val_root_mean_squared_error: 0.1277\n",
      "Epoch 9/10\n",
      "2917/2917 [==============================] - 29s 10ms/step - loss: 0.0106 - root_mean_squared_error: 0.0945 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1254\n",
      "Epoch 10/10\n",
      "2917/2917 [==============================] - 32s 11ms/step - loss: 0.0096 - root_mean_squared_error: 0.0891 - val_loss: 0.0167 - val_root_mean_squared_error: 0.1224\n"
     ]
    }
   ],
   "source": [
    "#training & evaluating the collaborative filtering recommender net\n",
    "embedding_size = 16\n",
    "model = RecommenderNet(num_users, num_items, embedding_size)\n",
    "\n",
    "model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=tf.keras.metrics.RootMeanSquaredError())\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_val, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da84f88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730/730 [==============================] - 2s 3ms/step - loss: 0.0160 - root_mean_squared_error: 0.1196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016012616455554962, 0.11959309875965118]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating the model\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ba0f4",
   "metadata": {},
   "source": [
    "Not bad, but there is always room for improvement.\n",
    "I'll try another approach:\n",
    "\n",
    "## Content similarity based recommender system\n",
    "### based on course description with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6d0032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\eneme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eneme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\eneme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc6dc043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COURSE_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ML0201EN</td>\n",
       "      <td>robots are coming  build iot apps with watson ...</td>\n",
       "      <td>have fun with iot and learn along the way  if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ML0122EN</td>\n",
       "      <td>accelerating deep learning with gpu</td>\n",
       "      <td>training complex deep learning models with lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPXX0ZG0EN</td>\n",
       "      <td>consuming restful services using the reactive ...</td>\n",
       "      <td>learn how to use a reactive jax rs client to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RP0105EN</td>\n",
       "      <td>analyzing big data in r using apache spark</td>\n",
       "      <td>apache spark is a popular cluster computing fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPXX0Z2PEN</td>\n",
       "      <td>containerizing  packaging  and running a sprin...</td>\n",
       "      <td>learn how to containerize  package  and run a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COURSE_ID                                              TITLE  \\\n",
       "0    ML0201EN  robots are coming  build iot apps with watson ...   \n",
       "1    ML0122EN                accelerating deep learning with gpu   \n",
       "2  GPXX0ZG0EN  consuming restful services using the reactive ...   \n",
       "3    RP0105EN         analyzing big data in r using apache spark   \n",
       "4  GPXX0Z2PEN  containerizing  packaging  and running a sprin...   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0  have fun with iot and learn along the way  if ...  \n",
       "1  training complex deep learning models with lar...  \n",
       "2  learn how to use a reactive jax rs client to a...  \n",
       "3  apache spark is a popular cluster computing fr...  \n",
       "4  learn how to containerize  package  and run a ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pulling course data frame for processing\n",
    "course_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/course_processed.csv\"\n",
    "course_content_df = pd.read_csv(course_url)\n",
    "course_content_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a0b74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging title and discription text fields\n",
    "course_content_df['course_texts'] = course_content_df[['TITLE', 'DESCRIPTION']].agg(' '.join, axis=1)\n",
    "course_content_df = course_content_df.reset_index()\n",
    "course_content_df['index'] = course_content_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1e5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for tokenization of course content\n",
    "def tokenize_course(course, keep_only_nouns=True):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(course)\n",
    "    # Remove English stop words and numbers\n",
    "    word_tokens = [w for w in word_tokens if (not w.lower() in stop_words) and (not w.isnumeric())]\n",
    "    # Only keep nouns \n",
    "    if keep_only_nouns:\n",
    "        filter_list = ['WDT', 'WP', 'WRB', 'FW', 'IN', 'JJR', 'JJS', 'MD', 'PDT', 'POS', 'PRP', 'RB', 'RBR', 'RBS',\n",
    "                       'RP']\n",
    "        tags = nltk.pos_tag(word_tokens)\n",
    "        word_tokens = [word for word, pos in tags if pos not in filter_list]\n",
    "\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6ecea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['robots',\n",
       " 'coming',\n",
       " 'build',\n",
       " 'iot',\n",
       " 'apps',\n",
       " 'watson',\n",
       " 'swift',\n",
       " 'red',\n",
       " 'fun',\n",
       " 'iot',\n",
       " 'learn',\n",
       " 'way',\n",
       " 'swift',\n",
       " 'developer',\n",
       " 'want',\n",
       " 'learn',\n",
       " 'iot',\n",
       " 'watson',\n",
       " 'ai',\n",
       " 'services',\n",
       " 'cloud',\n",
       " 'raspberry',\n",
       " 'pi',\n",
       " 'node',\n",
       " 'red',\n",
       " 'found',\n",
       " 'place',\n",
       " 'build',\n",
       " 'iot',\n",
       " 'apps',\n",
       " 'read',\n",
       " 'temperature',\n",
       " 'data',\n",
       " 'take',\n",
       " 'pictures',\n",
       " 'raspcam',\n",
       " 'use',\n",
       " 'ai',\n",
       " 'recognize',\n",
       " 'objects',\n",
       " 'pictures',\n",
       " 'program',\n",
       " 'irobot',\n",
       " 'create',\n",
       " 'robot']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize all courses\n",
    "tokens = [tokenize_course(course, True) for course in course_content_df['course_texts']]\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e38a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate bag of words dataframe\n",
    "token_dct = gensim.corpora.Dictionary(tokens)\n",
    "bow = [token_dct.doc2bow(course) for course in tokens]\n",
    "bow_dicts = {\"doc_index\": [],\n",
    "            \"doc_id\": [],\n",
    "            \"token\": [],\n",
    "            \"bow\": []}\n",
    "\n",
    "for course_idx, course_bow in enumerate(bow):    \n",
    "    for token_index, token_bow in course_bow:\n",
    "        bow_dicts['doc_index'].append(course_idx)\n",
    "        bow_dicts['doc_id'].append(course_content_df['COURSE_ID'].iloc[course_idx]) \n",
    "        bow_dicts['token'].append(token_dct[token_index])\n",
    "        bow_dicts['bow'].append(token_bow)\n",
    "bows_df = pd.DataFrame(bow_dicts)\n",
    "bows_df = bows_df[['doc_id', 'token', 'bow']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ce0e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to pivot union token of two BoWs \n",
    "def pivot_two_bows(basedoc, comparedoc):\n",
    "    base = basedoc.copy()\n",
    "    base['type'] = 'base'\n",
    "    compare = comparedoc.copy()\n",
    "    compare['type'] = 'compare'\n",
    "    # Append the two token sets vertically\n",
    "    join = base.append(compare)\n",
    "    # Pivot the two joined courses\n",
    "    joinT = join.pivot(index=['doc_id', 'type'], columns='token').fillna(0).reset_index(level=[0, 1])\n",
    "    # Assign columns\n",
    "    joinT.columns = ['doc_id', 'type'] + [t[1] for t in joinT.columns][2:]\n",
    "    return joinT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba6c136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>COURSE_ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>course_texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>157</td>\n",
       "      <td>ML0109EN</td>\n",
       "      <td>machine learning   dimensionality reduction</td>\n",
       "      <td>machine learning   dimensionality reduction</td>\n",
       "      <td>machine learning   dimensionality reduction ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>158</td>\n",
       "      <td>ML0101ENv3</td>\n",
       "      <td>machine learning with python</td>\n",
       "      <td>machine learning can be an incredibly benefici...</td>\n",
       "      <td>machine learning with python machine learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>200</td>\n",
       "      <td>ML0151EN</td>\n",
       "      <td>machine learning with r</td>\n",
       "      <td>this machine learning with r course dives into...</td>\n",
       "      <td>machine learning with r this machine learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>259</td>\n",
       "      <td>excourse46</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>machine learning is the science of getting com...</td>\n",
       "      <td>machine learning machine learning is the scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>excourse47</td>\n",
       "      <td>machine learning for all</td>\n",
       "      <td>machine learning  often called artificial inte...</td>\n",
       "      <td>machine learning for all machine learning  oft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>excourse60</td>\n",
       "      <td>introduction to tensorflow for artificial inte...</td>\n",
       "      <td>if you are a software developer who wants to b...</td>\n",
       "      <td>introduction to tensorflow for artificial inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index   COURSE_ID                                              TITLE  \\\n",
       "157    157    ML0109EN        machine learning   dimensionality reduction   \n",
       "158    158  ML0101ENv3                       machine learning with python   \n",
       "200    200    ML0151EN                            machine learning with r   \n",
       "259    259  excourse46                                   machine learning   \n",
       "260    260  excourse47                           machine learning for all   \n",
       "273    273  excourse60  introduction to tensorflow for artificial inte...   \n",
       "\n",
       "                                           DESCRIPTION  \\\n",
       "157        machine learning   dimensionality reduction   \n",
       "158  machine learning can be an incredibly benefici...   \n",
       "200  this machine learning with r course dives into...   \n",
       "259  machine learning is the science of getting com...   \n",
       "260  machine learning  often called artificial inte...   \n",
       "273  if you are a software developer who wants to b...   \n",
       "\n",
       "                                          course_texts  \n",
       "157  machine learning   dimensionality reduction ma...  \n",
       "158  machine learning with python machine learning ...  \n",
       "200  machine learning with r this machine learning ...  \n",
       "259  machine learning machine learning is the scien...  \n",
       "260  machine learning for all machine learning  oft...  \n",
       "273  introduction to tensorflow for artificial inte...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finally find all courses similar to those I was particulary interested in\n",
    "#generate two data frames with the course mentioned above and everythind besides that one\n",
    "course_ml = course_content_df[course_content_df['COURSE_ID'] == 'ML0101ENv3']\n",
    "df2 =bows_df[bows_df['doc_id'] != 'ML0101ENv3']\n",
    "bow_ml = bows_df[bows_df['doc_id'] == 'ML0101ENv3']\n",
    "similar_ids =[]\n",
    "for course in course_content_df['COURSE_ID']:\n",
    "    pivot = pivot_two_bows(bows_df[bows_df['doc_id'] == course], bow_ml)\n",
    "    similarity = 1 - cosine(pivot.iloc[0, 2:], pivot.iloc[1, 2:])\n",
    "    if similarity>0.5:\n",
    "        similar_ids.append(course)\n",
    "similar_df = course_content_df[course_content_df['COURSE_ID'].isin(similar_ids)]\n",
    "similar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dec17c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
